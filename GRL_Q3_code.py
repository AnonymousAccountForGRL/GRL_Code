# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u8LjfBXN9YvNgH_XJc43l-Qv6De4F72P
"""

import os
import torch
os.environ['TORCH'] = torch.__version__
print(torch.__version__)

!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html
!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html
!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git

import torch_geometric
import torch
import torch_scatter
import torch.nn as nn
import torch.nn.functional as F

import torch_geometric.nn as pyg_nn
import torch_geometric.utils as pyg_utils

from torch import Tensor
from typing import Union, Tuple, Optional
from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,
                                    OptTensor)

from torch.nn import Parameter, Linear
from torch_sparse import SparseTensor, set_diag
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.utils import remove_self_loops, add_self_loops, softmax

"""##Model Definition"""

def accuracy(pred_y,y):
  return ((pred_y == y).sum() / len(y)).item()

class GraphModel(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, args,embedding=False):
        super(GraphModel, self).__init__()
        conv_model=GATConv
        if args["model_type"]=='GAT':
          conv_model=GAT
        elif args["model_type"]=='GATv2':
          conv_model=GATv2
        elif args["model_type"]=='GATConvv2':
          conv_model=GATConvv2
        elif args["model_type"]=='GCN':
          conv_model=GCN
        elif args["model_type"]=='GCN_sum':
          conv_model=GCN_sum
        self.convs = nn.ModuleList()
        print("heads")
        print(args["heads"])
        self.convs.append(conv_model(input_dim, hidden_dim, heads=args["heads"],dropout=args["dropout"]))
        for l in range(args["num_layers"]-1):
            self.convs.append(conv_model(args["heads"] * hidden_dim, hidden_dim,heads=args["heads"]))
        # post-message-passing
        self.post_mp = nn.Sequential(
            nn.Linear(args["heads"] * hidden_dim, hidden_dim), nn.Dropout(args["dropout"]), 
            nn.Linear(hidden_dim, output_dim))
        self.dropout = args["dropout"]
        self.num_layers = args["num_layers"]
        self.embedding=embedding
        self.attention=None
    def forward(self, data):
        if(self.embedding==False):
          x, edge_index, batch = data.x, data.edge_index, data.batch   
        else:
          x, edge_index=data.x, data.edge_index
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
            #self.attention=self.convs[i].getAttention()
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout)
        x = self.post_mp(x)
        return F.log_softmax(x, dim=1)
    def generate_emb(self,data):
        x, edge_index=data.x, data.edge_index
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
        return x
    def loss(self, pred, label):
        return F.cross_entropy(pred, label)
    def minmaxAttention(self):
        print(self.attention)

"""##GCN definition

###fixed normalized aggergation
"""

import torch
from torch.nn import Linear, Parameter
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree

class GCN(MessagePassing):
    def __init__(self, in_channels, out_channels,heads=1,dropout=0):
        super().__init__(aggr='add')  # "Add" aggregation (Step 5).
        self.lin = Linear(in_channels, out_channels, bias=False)
        self.bias = Parameter(torch.Tensor(out_channels))
        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        self.bias.data.zero_()

    def forward(self, x, edge_index):
        # x has shape [N, in_channels]
        # edge_index has shape [2, E]

        # Step 1: Add self-loops to the adjacency matrix.
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

        # Step 2: Linearly transform node feature matrix.
        x = self.lin(x)

        # Step 3: Compute normalization.
        row, col = edge_index
        deg = degree(col, x.size(0), dtype=x.dtype)
        deg_inv_sqrt = deg.pow(-0.5)
        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
        norm = deg_inv_sqrt[row] + deg_inv_sqrt[col]

        # Step 4-5: Start propagating messages.
        out = self.propagate(edge_index, x=x, norm=norm)

        # Step 6: Apply a final bias vector.
        out += self.bias

        return out

    def message(self, x_j, norm):
        # x_j has shape [E, out_channels]

        # Step 4: Normalize node features.
        return norm.view(-1, 1) * x_j

"""###fixed aggregation: sum"""

'''
import torch
from torch.nn import Linear, Parameter
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree
import torch_geometric.utils as U
class GCN_sum(MessagePassing):
    def __init__(self, in_channels, out_channels,heads=1,dropout=0):
        super().__init__(aggr='add')  # "Add" aggregation (Step 5).
        self.w1=nn.Linear(in_channels,out_channels)
        self.w2=nn.Linear(in_channels,out_channels)
        self.reset_parameters()

    def reset_parameters(self):
        self.w1.reset_parameters()
        self.w2.reset_parameters()
        #self.bias.data.zero_()

    def forward(self, x, edge_index):
        edge_index = U.to_dense_adj(edge_index).squeeze(0)
        propagated_msgs=torch.mm(edge_index, x)
        potential_msgs=self.w2(propagated_msgs)
        root_update=self.w1(x)
        output = potential_msgs + root_update #+ self.bias
        return output
    def message(self, x_j):
        # x_j has shape [E, out_channels]

        # Step 4: Normalize node features.
        out = x_j
        return out
'''

'''
import torch
from torch.nn import Linear, Parameter
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree

class GCN_sum(MessagePassing):
    def __init__(self, in_channels, out_channels,heads=1,dropout=0):
        super().__init__(aggr='add')  # "Add" aggregation (Step 5).
        self.lin = Linear(in_channels, out_channels, bias=False)
        self.linr = Linear(in_channels, out_channels, bias=False)
        self.bias = Parameter(torch.Tensor(out_channels))
        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        self.linr.reset_parameters()
        self.bias.data.zero_()

    def forward(self, x, edge_index):
        prop = self.propagate(edge_index, x=(x, x))
        out = self.lin(x) + self.linr(prop)
        # Step 6: Apply a final bias vector.
        out += self.bias

        return out

    def message(self, x_j):
        # x_j has shape [E, out_channels]

        # Step 4: Normalize node features.
        out = x_j
        return out
'''

import torch_geometric.utils as U
class GCN_sum(nn.Module):
    
    def __init__(self, input_dim, output_dim, heads=1,dropout=0):
      super().__init__()
      #self.input_dim = input_dim
      #self.output_dim = output_dim
      #self.W2 = Parameter(torch.rand((input_dim, output_dim), dtype=torch.float32))
      #self.W1 = Parameter(torch.rand((input_dim, output_dim), dtype=torch.float32))
      #self.bias = Parameter(torch.zeros(output_dim, dtype=torch.float32))
      self.w1=nn.Linear(input_dim,output_dim)
      self.w2=nn.Linear(input_dim,output_dim)


    def forward(self, node_feats, adj_matrix):
      #potential_msgs = torch.mm(node_feats, self.W2)
      #propagated_msgs = torch.mm(adj_matrix, potential_msgs)
      #root_update = torch.mm(node_feats, self.W1)
      #adj_matrix = U.to_dense_adj(adj_matrix).squeeze(0)
      num_nodes=node_feats.size()[0]
       # batch = torch.zeros(size=num_nodes,dtype=torch.long)
      adj = U.to_dense_adj(adj_matrix,max_num_nodes=num_nodes).squeeze(0)
      propagated_msgs=torch.mm(adj, node_feats)
      potential_msgs=self.w2(propagated_msgs)
      root_update=self.w1(node_feats)
      output = potential_msgs + root_update #+ self.bias
      return output

"""##GAT Definition

GAT_layer, torch geometric implementation
"""

from typing import Optional, Tuple, Union

import torch
import torch.nn.functional as F
from torch import Tensor
from torch.nn import Parameter
from torch_sparse import SparseTensor, set_diag

from torch_geometric.nn.conv import MessagePassing
from torch_geometric.nn.dense.linear import Linear
from torch_geometric.typing import NoneType  # noqa
from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size
from torch_geometric.utils import add_self_loops, remove_self_loops, softmax

from torch_geometric.nn.inits import glorot, zeros
class GATConv(MessagePassing):
    def __init__(
        self,
        in_channels: Union[int, Tuple[int, int]],
        out_channels: int,
        heads: int,
        concat: bool = True,
        negative_slope: float = 0.2,
        dropout: float = 0.6,
        add_self_loops: bool = True,
        edge_dim: Optional[int] = None,
        fill_value: Union[float, Tensor, str] = 'mean',
        bias: bool = True,
        **kwargs,
    ):
        kwargs.setdefault('aggr', 'add')
        super().__init__(node_dim=0, **kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.concat = concat
        self.negative_slope = negative_slope
        self.dropout = dropout
        self.add_self_loops = add_self_loops
        self.edge_dim = edge_dim
        self.fill_value = fill_value

        # In case we are operating in bipartite graphs, we apply separate
        # transformations 'lin_src' and 'lin_dst' to source and target nodes:
        if isinstance(in_channels, int):
            self.lin_src = Linear(in_channels, heads * out_channels,
                                  bias=False, weight_initializer='glorot')
            self.lin_dst = self.lin_src
        else:
            self.lin_src = Linear(in_channels[0], heads * out_channels, False,
                                  weight_initializer='glorot')
            self.lin_dst = Linear(in_channels[1], heads * out_channels, False,
                                  weight_initializer='glorot')

        # The learnable parameters to compute attention coefficients:
        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))
        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))

        if edge_dim is not None:
            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False,
                                   weight_initializer='glorot')
            self.att_edge = Parameter(torch.Tensor(1, heads, out_channels))
        else:
            self.lin_edge = None
            self.register_parameter('att_edge', None)

        if bias and concat:
            self.bias = Parameter(torch.Tensor(heads * out_channels))
        elif bias and not concat:
            self.bias = Parameter(torch.Tensor(out_channels))
        else:
            self.register_parameter('bias', None)

        self.reset_parameters()
    def reset_parameters(self):
        self.lin_src.reset_parameters()
        self.lin_dst.reset_parameters()
        if self.lin_edge is not None:
            self.lin_edge.reset_parameters()
        glorot(self.att_src)
        glorot(self.att_dst)
        glorot(self.att_edge)
        zeros(self.bias)
    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,
                edge_attr: OptTensor = None, size: Size = None,
                return_attention_weights=None):
        # type: (Union[Tensor, OptPairTensor], Tensor, OptTensor, Size, NoneType) -> Tensor  # noqa
        # type: (Union[Tensor, OptPairTensor], SparseTensor, OptTensor, Size, NoneType) -> Tensor  # noqa
        # type: (Union[Tensor, OptPairTensor], Tensor, OptTensor, Size, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa
        # type: (Union[Tensor, OptPairTensor], SparseTensor, OptTensor, Size, bool) -> Tuple[Tensor, SparseTensor]  # noqa
        r"""
        Args:
            return_attention_weights (bool, optional): If set to :obj:`True`,
                will additionally return the tuple
                :obj:`(edge_index, attention_weights)`, holding the computed
                attention weights for each edge. (default: :obj:`None`)
        """
        # NOTE: attention weights will be returned whenever
        # `return_attention_weights` is set to a value, regardless of its
        # actual value (might be `True` or `False`). This is a current somewhat
        # hacky workaround to allow for TorchScript support via the
        # `torch.jit._overload` decorator, as we can only change the output
        # arguments conditioned on type (`None` or `bool`), not based on its
        # actual value.

        H, C = self.heads, self.out_channels

        # We first transform the input node features. If a tuple is passed, we
        # transform source and target node features via separate weights:
        if isinstance(x, Tensor):
            assert x.dim() == 2, "Static graphs not supported in 'GATConv'"
            x_src = x_dst = self.lin_src(x).view(-1, H, C)
        else:  # Tuple of source and target node features:
            x_src, x_dst = x
            assert x_src.dim() == 2, "Static graphs not supported in 'GATConv'"
            x_src = self.lin_src(x_src).view(-1, H, C)
            if x_dst is not None:
                x_dst = self.lin_dst(x_dst).view(-1, H, C)

        x = (x_src, x_dst)

        # Next, we compute node-level attention coefficients, both for source
        # and target nodes (if present):
        alpha_src = (x_src * self.att_src).sum(dim=-1)
        alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)
        alpha = (alpha_src, alpha_dst)

        if self.add_self_loops:
            if isinstance(edge_index, Tensor):
                # We only want to add self-loops for nodes that appear both as
                # source and target nodes:
                num_nodes = x_src.size(0)
                if x_dst is not None:
                    num_nodes = min(num_nodes, x_dst.size(0))
                num_nodes = min(size) if size is not None else num_nodes
                edge_index, edge_attr = remove_self_loops(
                    edge_index, edge_attr)
                edge_index, edge_attr = add_self_loops(
                    edge_index, edge_attr, fill_value=self.fill_value,
                    num_nodes=num_nodes)
            elif isinstance(edge_index, SparseTensor):
                if self.edge_dim is None:
                    edge_index = set_diag(edge_index)
                else:
                    raise NotImplementedError(
                        "The usage of 'edge_attr' and 'add_self_loops' "
                        "simultaneously is currently not yet supported for "
                        "'edge_index' in a 'SparseTensor' form")

        # edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)
        alpha = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr)

        # propagate_type: (x: OptPairTensor, alpha: Tensor)
        out = self.propagate(edge_index, x=x, alpha=alpha, size=size)

        if self.concat:
            out = out.view(-1, self.heads * self.out_channels)
        else:
            out = out.mean(dim=1)

        if self.bias is not None:
            out = out + self.bias

        if isinstance(return_attention_weights, bool):
            if isinstance(edge_index, Tensor):
                return out, (edge_index, alpha)
            elif isinstance(edge_index, SparseTensor):
                return out, edge_index.set_value(alpha, layout='coo')
        else:
            return out
    def edge_update(self, alpha_j: Tensor, alpha_i: OptTensor,
                    edge_attr: OptTensor, index: Tensor, ptr: OptTensor,
                    size_i: Optional[int]) -> Tensor:
        # Given edge-level attention coefficients for source and target nodes,
        # we simply need to sum them up to "emulate" concatenation:
        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i

        if edge_attr is not None and self.lin_edge is not None:
            if edge_attr.dim() == 1:
                edge_attr = edge_attr.view(-1, 1)
            edge_attr = self.lin_edge(edge_attr)
            edge_attr = edge_attr.view(-1, self.heads, self.out_channels)
            alpha_edge = (edge_attr * self.att_edge).sum(dim=-1)
            alpha = alpha + alpha_edge

        alpha = F.leaky_relu(alpha, self.negative_slope)
        alpha = softmax(alpha, index, ptr, size_i)
        alpha = F.dropout(alpha, p=self.dropout, training=self.training)
        return alpha


    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:
        return alpha.unsqueeze(-1) * x_j

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}({self.in_channels}, '
                f'{self.out_channels}, heads={self.heads})')

'''
class GAT(MessagePassing):
    def __init__(self, in_dim, out_dim, heads=8,
                 negative_slope = 0.2, dropout = 0.6, **kwargs):
        super(GAT, self).__init__(node_dim=0, **kwargs)
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.heads = heads
        self.negative_slope = negative_slope
        self.dropout = dropout
        self.att_l = None
        self.att_r = None
        self.lin_l = nn.Linear(self.in_dim, self.out_dim * self.heads)
        self.lin_r = self.lin_l
        self.att_l = nn.Parameter(torch.zeros(self.heads, self.out_dim))
        self.att_r = nn.Parameter(torch.zeros(self.heads, self.out_dim))
        self.attention = None
       # self.reset_parameters()

    def param_init(self):
  
      def _reset_module_parameters(module):
            for layer in module.children():
                if hasattr(layer, 'reset_parameters'):
                    layer.reset_parameters()
                elif hasattr(layer, 'children'):
                    for child_layer in layer.children():
                        _reset_module_parameters(child_layer)

      _reset_module_parameters(self)
    #def reset_parameters(self):
  #      nn.init.xavier_uniform_(self.lin_l.weight)
    #    nn.init.xavier_uniform_(self.lin_r.weight)
   #     nn.init.xavier_uniform_(self.att_l)
   #     nn.init.xavier_uniform_(self.att_r)

    def forward(self, x, edge_index, size = None):
        H, C = self.heads, self.out_dim
        x_l = self.lin_l(x).reshape(-1, H, C)
        x_r = self.lin_r(x).reshape(-1, H, C)
        alpha_l = self.att_l * x_l
        alpha_r = self.att_r * x_r
        out = self.propagate(edge_index, x=(x_l, x_r), alpha=(alpha_l, alpha_r), size=size)
        out = out.reshape(-1, H*C)
        return out

    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):
        alpha = F.leaky_relu(alpha_i + alpha_j, negative_slope=self.negative_slope)
        if ptr:
            att_weight = F.softmax(alpha_i + alpha_j, ptr)
        else:
            att_weight = torch_geometric.utils.softmax(alpha_i + alpha_j, index)
        att_weight = F.dropout(att_weight, p=self.dropout)
        self.attention=att_weight
        out = att_weight * x_j
        return out
    def getAttention(self):
        return self.attention
    def aggregate(self, inputs, index, dim_size = None):
        out = torch_scatter.scatter(inputs, index, self.node_dim, dim_size=dim_size, reduce='sum')
        return out
'''

"""GATv2, torch geometric implementation"""

from typing import Optional, Tuple, Union

import torch
import torch.nn.functional as F
from torch import Tensor
from torch.nn import Parameter
from torch_sparse import SparseTensor, set_diag

from torch_geometric.nn.conv import MessagePassing
from torch_geometric.nn.dense.linear import Linear
from torch_geometric.nn.inits import glorot, zeros
from torch_geometric.typing import Adj, OptTensor, PairTensor
from torch_geometric.utils import add_self_loops, remove_self_loops, softmax

class GATConvv2(MessagePassing):
    _alpha: OptTensor

    def __init__(
        self,
        in_channels: Union[int, Tuple[int, int]],
        out_channels: int,
        heads: int,
        concat: bool = True,
        negative_slope: float = 0.2,
        dropout: float = 0.0,
        add_self_loops: bool = True,
        edge_dim: Optional[int] = None,
        fill_value: Union[float, Tensor, str] = 'mean',
        bias: bool = True,
        share_weights: bool = False,
        **kwargs,
    ):
        super().__init__(node_dim=0, **kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.concat = concat
        self.negative_slope = negative_slope
        self.dropout = dropout
        self.add_self_loops = add_self_loops
        self.edge_dim = edge_dim
        self.fill_value = fill_value
        self.share_weights = share_weights

        if isinstance(in_channels, int):
            self.lin_l = Linear(in_channels, heads * out_channels, bias=bias,
                                weight_initializer='glorot')
            if share_weights:
                self.lin_r = self.lin_l
            else:
                self.lin_r = Linear(in_channels, heads * out_channels,
                                    bias=bias, weight_initializer='glorot')
        else:
            self.lin_l = Linear(in_channels[0], heads * out_channels,
                                bias=bias, weight_initializer='glorot')
            if share_weights:
                self.lin_r = self.lin_l
            else:
                self.lin_r = Linear(in_channels[1], heads * out_channels,
                                    bias=bias, weight_initializer='glorot')

        self.att = Parameter(torch.Tensor(1, heads, out_channels))

        if edge_dim is not None:
            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False,
                                   weight_initializer='glorot')
        else:
            self.lin_edge = None

        if bias and concat:
            self.bias = Parameter(torch.Tensor(heads * out_channels))
        elif bias and not concat:
            self.bias = Parameter(torch.Tensor(out_channels))
        else:
            self.register_parameter('bias', None)

        self._alpha = None

        self.reset_parameters()


    def reset_parameters(self):
        self.lin_l.reset_parameters()
        self.lin_r.reset_parameters()
        if self.lin_edge is not None:
            self.lin_edge.reset_parameters()
        glorot(self.att)
        zeros(self.bias)



    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,
                edge_attr: OptTensor = None,
                return_attention_weights: bool = None):
        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, NoneType) -> Tensor  # noqa
        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, NoneType) -> Tensor  # noqa
        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa
        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, bool) -> Tuple[Tensor, SparseTensor]  # noqa
        r"""
        Args:
            return_attention_weights (bool, optional): If set to :obj:`True`,
                will additionally return the tuple
                :obj:`(edge_index, attention_weights)`, holding the computed
                attention weights for each edge. (default: :obj:`None`)
        """
        H, C = self.heads, self.out_channels

        x_l: OptTensor = None
        x_r: OptTensor = None
        if isinstance(x, Tensor):
            assert x.dim() == 2
            x_l = self.lin_l(x).view(-1, H, C)
            if self.share_weights:
                x_r = x_l
            else:
                x_r = self.lin_r(x).view(-1, H, C)
        else:
            x_l, x_r = x[0], x[1]
            assert x[0].dim() == 2
            x_l = self.lin_l(x_l).view(-1, H, C)
            if x_r is not None:
                x_r = self.lin_r(x_r).view(-1, H, C)

        assert x_l is not None
        assert x_r is not None

        if self.add_self_loops:
            if isinstance(edge_index, Tensor):
                num_nodes = x_l.size(0)
                if x_r is not None:
                    num_nodes = min(num_nodes, x_r.size(0))
                edge_index, edge_attr = remove_self_loops(
                    edge_index, edge_attr)
                edge_index, edge_attr = add_self_loops(
                    edge_index, edge_attr, fill_value=self.fill_value,
                    num_nodes=num_nodes)
            elif isinstance(edge_index, SparseTensor):
                if self.edge_dim is None:
                    edge_index = set_diag(edge_index)
                else:
                    raise NotImplementedError(
                        "The usage of 'edge_attr' and 'add_self_loops' "
                        "simultaneously is currently not yet supported for "
                        "'edge_index' in a 'SparseTensor' form")

        # propagate_type: (x: PairTensor, edge_attr: OptTensor)
        out = self.propagate(edge_index, x=(x_l, x_r), edge_attr=edge_attr,
                             size=None)

        alpha = self._alpha
        self._alpha = None

        if self.concat:
            out = out.view(-1, self.heads * self.out_channels)
        else:
            out = out.mean(dim=1)

        if self.bias is not None:
            out = out + self.bias

        if isinstance(return_attention_weights, bool):
            assert alpha is not None
            if isinstance(edge_index, Tensor):
                return out, (edge_index, alpha)
            elif isinstance(edge_index, SparseTensor):
                return out, edge_index.set_value(alpha, layout='coo')
        else:
            return out


    def message(self, x_j: Tensor, x_i: Tensor, edge_attr: OptTensor,
                index: Tensor, ptr: OptTensor,
                size_i: Optional[int]) -> Tensor:
        x = x_i + x_j

        if edge_attr is not None:
            if edge_attr.dim() == 1:
                edge_attr = edge_attr.view(-1, 1)
            assert self.lin_edge is not None
            edge_attr = self.lin_edge(edge_attr)
            edge_attr = edge_attr.view(-1, self.heads, self.out_channels)
            x = x + edge_attr

        x = F.leaky_relu(x, self.negative_slope)
        alpha = (x * self.att).sum(dim=-1)
        alpha = softmax(alpha, index, ptr, size_i)
        self._alpha = alpha
        alpha = F.dropout(alpha, p=self.dropout, training=self.training)
        return x_j * alpha.unsqueeze(-1)

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}({self.in_channels}, '
                f'{self.out_channels}, heads={self.heads})')

"""##Improve Training with Early Stopping"""

import time

import networkx as nx
import numpy as np
import torch
import torch.optim as optim

from torch_geometric.datasets import TUDataset
from torch_geometric.datasets import Planetoid
from torch_geometric.datasets import PPI
from torch_geometric.data import DataLoader

import torch_geometric.nn as pyg_nn

import matplotlib.pyplot as plt


def train(dataset, args):
    
    print("Node task. test set size:", np.sum(dataset[0]['train_mask'].numpy()))
    test_loader = loader = DataLoader(dataset, batch_size=args["batch_size"], shuffle=True)

    # build model
    model = GraphModel(dataset.num_node_features, args["hidden_dim"], dataset.num_classes,args,False)
    filter_fn = filter(lambda p : p.requires_grad, model.parameters())
    opt = optim.Adam(filter_fn, lr=args["lr"], weight_decay=args["weight_decay"])
    #scheduler = optim.lr_scheduler.StepLR(opt, step_size=args["opt_decay_step"], gamma=args["opt_decay_rate"])
    # train
    losses = []
    test_accs = []
    train_acc=[]
    oldloss=0
    newloss=0
    round = 0
    for epoch in range(args["epochs"]):
        total_loss = 0
        model.train()
        train_accuracies=0
        for batch in loader:
            opt.zero_grad()
            pred = model(batch)
            label = batch.y
            pred = pred[batch.train_mask]     
            label = label[batch.train_mask]
            loss = model.loss(pred, label)
            loss.backward()
            opt.step()
            total_loss += loss.item() * batch.num_graphs
            train_pred=pred.argmax(dim=1)
            correct = train_pred.eq(label).sum().item()
            total =torch.sum(batch.train_mask).item()
            train_accuracies=correct/total
            if epoch%10==0:
              train_acc.append(train_accuracies)
        total_loss /= len(loader.dataset)
        losses.append(total_loss)
        
        #if epoch % 10 == 0:
        test_acc = test(test_loader, model)
        test_accs.append(test_acc)
         
          #print("Epoch ", epoch, "Loss: ", total_loss, "Train Acc: ", train_accuracies, "Test Acc.: ", test_acc)
        #else:
        #  test_accs.append(test_accs[-1])
        mask = dataset[0].val_mask
        pred = model(dataset[0])
        label = dataset[0].y
        pred = pred[mask]
        label = dataset[0].y[mask]
        ct= nn.CrossEntropyLoss()
        newloss=ct(pred,label)
        if newloss>=oldloss:
          round+=1
        else:
          round=0
        
        if round == 50:
            print('Early stopping at epoch ',epoch)
            #print('Best Val Accuracy', best_val_acc)
            break
        
        oldloss=newloss
    print()
    return test_accs, losses, model

def test(loader, model, is_validation=True):
    model.eval()
    correct = 0
    for data in loader:
        with torch.no_grad():
            # max(dim=1) returns values, indices tuple; only need indices
            pred = model(data).max(dim=1)[1]
            label = data.y

        mask = data.val_mask if is_validation else data.test_mask
        # node classification: only evaluate on nodes in test set
        pred = pred[mask]
        label = data.y[mask]
        correct += pred.eq(label).sum().item()

    total = 0
    for data in loader.dataset:
        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()
    return correct / total
  
class objectview(object):
    def __init__(self, d):
        self.__dict__ = d

@torch.no_grad()
def testacc(model, data):
    """Evaluate the model on test set and print the accuracy score."""
    
    model.embedding=True
    model.eval()
    out = model(data[0])
    acc = accuracy(out.argmax(dim=1)[data[0].test_mask], data[0].y[data[0].test_mask])
    return acc

args={'model_type': 'GAT', 'dataset': 'Cora', 'num_layers': 2, 'heads': 2, 
         'batch_size': 32, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 30, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
if args["dataset"] == 'Cora':
  dataset=Planetoid(root=".", name="Cora")
else: 
  dataset=Planetoid(root=".", name="Citeseer")
test_accs, losses, model_GATConv = train(dataset, args) 
print("Maximum accuracy: {0}".format(max(test_accs)))
print("Minimum loss: {0}".format(min(losses)))
test_acc=testacc(model_GATConv,dataset)
print(test_acc)
model_GATConv.minmaxAttention()
plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
plt.plot(losses, label="training loss" + " - " + args["model_type"])
plt.plot(test_accs, label="val accuracy" + " - " + args["model_type"])
plt.legend()
plt.show()

"""##Visualization functions"""

def accuracy(pred_y,y):
  return ((pred_y == y).sum() / len(y)).item()

from torch_geometric.utils import degree
def generateGraph(model):
  dataset = Planetoid(root='.', name="Cora")
  
  data=dataset[0]
  model.embedding=True
# Get model's classifications
  out = model(data)

# Calculate the degree of each node
  degrees = degree(data.edge_index[0]).numpy()

# Store accuracy scores and sample sizes
  accuracies = []
  sizes = []

# Accuracy for degrees between 0 and 5
  for i in range(0, 6):
    mask = np.where(degrees == i)[0]
    accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))
    sizes.append(len(mask))

# Accuracy for degrees > 5
  mask = np.where(degrees > 5)[0]
  accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))
  sizes.append(len(mask))

# Bar plot
  fig, ax = plt.subplots(figsize=(18, 9))
  plt.ylim(0, 1)
  ax.set_xlabel('Node degree')
  ax.set_ylabel('Accuracy score')
  plt.bar(['0','1','2','3','4','5','>5'],accuracies,color=(0.2, 0.4, 0.6, 0.6))
  for i in range(0, 7):
    plt.text(i, accuracies[i], f'{accuracies[i]*100:.2f}%', ha='center', color=(0.2, 0.4, 0.6, 0.6))
  for i in range(0, 7):
    plt.text(i, accuracies[i]//2, sizes[i],ha='center', color='white')
  plt.show()

import pandas as pd
import warnings
import matplotlib.pyplot as plt

from sklearn.manifold import TSNE

def dimension_reduction(model: nn.Module):
  """
    Args:
      model: model object for generating features
    
    Return:
      pd.DataFrame: A data frame that has 'dimension 1', 'dimension 2', and 'labels' as a column
  """
    ## ------ Begin Solution ------ ##
  model.emb=True
  dataset = Planetoid(root='.', name="Cora")
  data=dataset[0]
  emb = (model.generate_emb(data)).detach().numpy()
  #emb=emb[data.val_mask]
  y=data.y[data.val_mask]
  t=TSNE(n_components=2).fit_transform(emb)[data["val_mask"]]
  data = {'dimension 1':t[:,0], 'dimension 2':t[:,1], 'labels':y}
  df = pd.DataFrame(data)
  plt.scatter(df['dimension 1'], df['dimension 2'], c=df['labels'])
  plt.show()

"""## Parameter Tuning
try combination of different datasets, different batch size and different hidden_dim, to search the best combination
"""

def main():
  args={'model_type': 'GATConv', 'dataset': 'cora', 'num_layers': 2, 'heads': 2, 
         'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  for ds in ['Cora','Citeseer']:
    for mt in['GATConv','GAT']:
      for hd in [32,64]:
        for bs in[32,64]:
          for heads in [1,2,4,8]:
            args["model_type"]=mt
            args["dataset"]=ds
            args["batch_size"]=bs
            args["hidden_dim"]=hd
            args["heads"]=heads

            print(args)
            if args["dataset"] == 'Cora':
              dataset=Planetoid(root=".", name="Cora")
            else: 
              dataset=Planetoid(root=".", name="Citeseer")
            test_accs, losses, model = train(dataset, args) 
            print("Maximum accuracy: {0}".format(max(test_accs)))
            print("Minimum loss: {0}".format(min(losses)))
            plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
            plt.plot(losses, label="training loss" + " - " + args["model_type"])
            plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
            plt.legend()
            plt.show()
    
if __name__ == '__main__':
    main()

"""##GCN with node normalised, tune with the same setting

###GCN normalised, cora
"""

acc_GCNnorm=[]
best_GCNnorm=0
for count in range(5):
  args={'model_type': 'GCN', 'dataset': 'Cora', 'num_layers': 2, 'heads': 1, 
         'batch_size': 32, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GCNnorm:
    acc_GCNnorm=test_accs
    best_GCNnorm=test_acc
  print(test_acc)
 # generateGraph(model)
  #dimension_reduction(model)
  plt.legend()
  plt.show()

"""###GCN normalised, Citeseer"""

acc_GCNnorm_Citeseer=[]
best_GCNnorm_Citeseer=0
for count in range(5):
  args={'model_type': 'GCN', 'dataset': 'Citeseer', 'num_layers': 2, 'heads': 1, 
         'batch_size': 32, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 300, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer",split="random")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GCNnorm_Citeseer:
    acc_GCNnorm_Citeseer=test_accs
    best_GCNnorm_Citeseer=test_acc
  print(test_acc)
  #generateGraph(model)
  #dimension_reduction(model)
  plt.legend()
  plt.show()

"""##GCN with sum aggregation, not normalised

###cora
"""

acc_GCNsum=[]
best_GCNsum=0
for count in range(5):
  args={'model_type': 'GCN_sum', 'dataset': 'Cora', 'num_layers': 2, 'heads': 1, 
         'batch_size': 32, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GCNsum:
    acc_GCNsum=test_accs
    best_GCNsum=test_acc
  print(test_acc)
  generateGraph(model)
  dimension_reduction(model)
  plt.legend()
  plt.show()

"""###Citeseer"""

acc_GCNsum_Citeseer=[]
best_GCNsum_Citeseer=0
for count in range(5):
  args={'model_type': 'GCN_sum', 'dataset': 'Citeseer', 'num_layers': 2, 'heads': 1, 
         'batch_size': 32, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 300, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer",split="random")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GCNsum_Citeseer:
    acc_GCNsum_Citeseer=test_accs
    best_GCNsum_Citeseer=test_acc
  print(test_acc)
  #generateGraph(model)
  #dimension_reduction(model)
  plt.legend()
  plt.show()

"""##GAT attention aggregation

###cora
"""

acc_GAT=[]
best_GAT=0
for count in range(5):
  args={'model_type': 'GATConv', 'dataset': 'Cora', 'num_layers': 2, 'heads': 8, 
         'batch_size': 32, 'hidden_dim': 8, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GAT:
    acc_GAT=test_accs
    best_GAT=test_acc
  print(test_acc)
  generateGraph(model)
  dimension_reduction(model)
  plt.legend()
  plt.show()

"""###citeseer"""

acc_GAT_Citeseer=[]
best_GAT_Citeseer=0
for count in range(5):
  args={'model_type': 'GATConv', 'dataset': 'Citeseer', 'num_layers': 2, 'heads': 8, 
         'batch_size': 32, 'hidden_dim': 8, 'dropout': 0.6, 'epochs': 300, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer",split="random")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GAT_Citeseer:
    acc_GAT_Citeseer=test_accs
    best_GAT_Citeseer=test_acc
  print(test_acc)
  #generateGraph(model)
 # dimension_reduction(model)
  plt.legend()
  plt.show()

"""##GATv2

###cora
"""

acc_GATv2=[]
best_GATv2=0
for count in range(5):
  args={'model_type': 'GATConvv2', 'dataset': 'Cora', 'num_layers': 2, 'heads': 8, 
         'batch_size': 32, 'hidden_dim': 8, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer")
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GATv2:
    acc_GATv2=test_accs
    best_GATv2=test_acc
  print(test_acc)
  #generateGraph(model)
  #dimension_reduction(model)
  plt.legend()
  plt.show()

"""###citeseer"""

acc_GATv2_Citeseer=[]
best_GATv2_Citeseer=0
for count in range(5):
  args={'model_type': 'GATConvv2', 'dataset': 'Citeseer', 'num_layers': 2, 'heads': 8, 
         'batch_size': 32, 'hidden_dim': 8, 'dropout': 0.6, 'epochs': 300, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  if args["dataset"] == 'Cora':
    dataset=Planetoid(root=".", name="Cora")
  else: 
    dataset=Planetoid(root=".", name="Citeseer",split='random')
  test_accs, losses, model = train(dataset, args) 
  print("Maximum accuracy: {0}".format(max(test_accs)))
  print("Minimum loss: {0}".format(min(losses)))
  plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
  plt.plot(losses, label="training loss" + " - " + args["model_type"])
  plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
  test_acc=testacc(model,dataset)
  if test_acc>best_GATv2_Citeseer:
    acc_GATv2_Citeseer=test_accs
    best_GATv2_Citeseer=test_acc
  print(test_acc)
  #generateGraph(model)
  #dimension_reduction(model)
  plt.legend()
  plt.show()

print(best_GCNnorm)
print(best_GCNsum)
print(best_GAT)
print(best_GATv2)

print(best_GCNnorm_Citeseer)
print(best_GCNsum_Citeseer)

print(best_GCNnorm_Citeseer)
print(best_GCNsum_Citeseer)
print(best_GAT_Citeseer)
print(best_GATv2_Citeseer)

"""##plot"""

plt.title("Cora")
plt.plot(acc_GCNnorm, color='blue',alpha=0.8, label="GCNnorm")
plt.plot(acc_GCNsum,color='green',alpha=0.8, label="GCNsum")
plt.plot(acc_GAT, color='pink',alpha=0.8,label="GAT")
plt.plot(acc_GATv2, color='yellow',alpha=0.8,label="GATv2")
plt.ylabel('val acc')
plt.xlabel('epoch')
plt.legend()
plt.show()

plt.title("Citeseer")
plt.plot(acc_GCNnorm_Citeseer, color='blue',alpha=0.8,label="GCN norm")
plt.plot(acc_GCNsum_Citeseer, color='green',alpha=0.8,label="GCNsum")
plt.plot(acc_GAT_Citeseer, color='pink',alpha=0.8,label="GAT")
plt.plot(acc_GATv2_Citeseer, color='yellow',alpha=0.8,label="GATv2")
plt.ylabel('val acc')
plt.xlabel('epoch')
plt.show()

"""##Does GAT help with over smoothing?"""

gcn_list=[]
args={'model_type': 'GCN', 'dataset': 'Cora', 'num_layers': 2, 'heads': 1, 
         'batch_size': 64, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
for num_layers in [1,2,3,4,5,6]:
    args["num_layers"]=num_layers
    if args["dataset"] == 'Cora':
        dataset=Planetoid(root=".", name="Cora")
    else: 
        dataset=Planetoid(root=".", name="Citeseer")
    test_accs, losses, model_conv = train(dataset, args) 
    print("Maximum accuracy: {0}".format(max(test_accs)))
    test_acc=testacc(model_conv,dataset)
    print(test_acc)
    #print("Minimum loss: {0}".format(min(losses)))
    #plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
    #plt.plot(losses, label="training loss" + " - " + args["model_type"])
    #plt.plot(test_accs, label="num_layers" + " = " + str(args["num_layers"]))
    gcn_list.append(test_accs)
    #generateGraph(model_conv)
    #dimension_reduction(model_conv)
for i in range(6):
  plt.plot(gcn_list[i], label="num_layers" + " = " + str(i))
plt.legend()
plt.title("GCN Oversmoothing")
plt.ylabel('val acc')
plt.xlabel('epoch')
plt.show()
gat_list=[]
args={'model_type': 'GATConv', 'dataset': 'Cora', 'num_layers': 2, 'heads': 8, 
         'batch_size': 64, 'hidden_dim': 8, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
for num_layers in [1,2,3,4,5,6]:
    args["num_layers"]=num_layers
    if args["dataset"] == 'Cora':
        dataset=Planetoid(root=".", name="Cora")
    else: 
        dataset=Planetoid(root=".", name="Citeseer")
    test_accs, losses, model_conv = train(dataset, args) 
    print("Maximum accuracy: {0}".format(max(test_accs)))
    test_acc=testacc(model_conv,dataset)
    print(test_acc)
    gat_list.append(test_accs)
    if num_layers==5 or num_layers==6:
        generateGraph(model_conv)
        dimension_reduction(model_conv)
for i in range(6):
  plt.plot(gat_list[i], label="num_layers" + " = " + str(i))
plt.legend()
plt.title("GAT Oversmoothing")
plt.ylabel('val acc')
plt.xlabel('epoch')
plt.show()



gat_accs=[]
num=[1,2,3,5,10]
args={'model_type': 'GATConv', 'dataset': 'Cora', 'num_layers': 2, 'heads': 8, 
         'batch_size': 64, 'hidden_dim': 8, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
for num_layers in [1,2,3,5,10]:
    args["num_layers"]=num_layers
    if args["dataset"] == 'Cora':
        dataset=Planetoid(root=".", name="Cora")
    else: 
        dataset=Planetoid(root=".", name="Citeseer")
    test_accs, losses, model_conv = train(dataset, args) 
    print("Maximum accuracy: {0}".format(max(test_accs)))
    test_acc=testacc(model_conv,dataset)
    print(test_acc)
    #print("Minimum loss: {0}".format(min(losses)))
    #plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
    #plt.plot(losses, label="training loss" + " - " + args["model_type"])
    #plt.plot(test_accs, label="num_layers" + " = " + args["num_layers"])
    gat_accs.append(test_accs)
    #generateGraph(model_conv)
    #dimension_reduction(model_conv)
for i in range(5):
  plt.plot(gat_accs[i], label="num_layers" + " = " + str(num[i]))
plt.legend()
plt.title("GAT Oversmoothing")
plt.ylabel('val acc')
plt.xlabel('epoch')
plt.show()

for i in range(5):
  plt.plot(gat_accs[i], label="num_layers" + " = " + str(num[i]))
plt.legend()
plt.title("GAT Oversmoothing")
plt.ylabel('val acc')
plt.xlabel('epoch')
plt.ylim(0,1)
plt.show()



"""##Compared with GCN oversmoothing"""

def main():
  args={'model_type': 'GCN', 'dataset': 'Cora', 'num_layers': 2, 'heads': 1, 
         'batch_size': 64, 'hidden_dim': 64, 'dropout': 0.6, 'epochs': 200, 
         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 
         'weight_decay': 5e-3, 'lr': 0.005}
  for num_layers in [1,2,3,4,5,6]:
      args["num_layers"]=num_layers
      if args["dataset"] == 'Cora':
        dataset=Planetoid(root=".", name="Cora")
      else: 
        dataset=Planetoid(root=".", name="Citeseer")
      test_accs, losses, model_conv = train(dataset, args) 
      print("Maximum accuracy: {0}".format(max(test_accs)))
      #print("Minimum loss: {0}".format(min(losses)))
      #plt.title(dataset.name+" "+  args["model_type"]+" "+str(args["batch_size"])+" "+str(args["hidden_dim"]))
      #plt.plot(losses, label="training loss" + " - " + args["model_type"])
      #plt.plot(test_accs, label="test accuracy" + " - " + args["model_type"])
      generateGraph(model_conv)
      dimension_reduction(model_conv)
      #plt.legend()
      #plt.show()
    
if __name__ == '__main__':
    main()

"""##PPI dataset"""

import os.path as osp

import torch
import torch.nn.functional as F
from torch_geometric.datasets import PPI
from torch_geometric.data import DataLoader

from sklearn import metrics

#path = osp.join(osp.dirname(osp.realpath(__file__)), 'data', 'PPI')
train_dataset = PPI(root=".", split='train')
val_dataset = PPI(root=".",  split='val')
test_dataset = PPI(root=".", split='test')
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)

    
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = GCN(train_dataset.num_features, 1024)
        self.lin1 = torch.nn.Linear(train_dataset.num_features,  1024)
        self.conv2 = GCN(1024, 1024)
        self.lin2 = torch.nn.Linear(1024, 1024)
        self.conv3 = GCN( 1024, train_dataset.num_classes)
        self.lin3 = torch.nn.Linear(1024, train_dataset.num_classes)

    def forward(self, x, edge_index):
        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))
        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))
        x = self.conv3(x, edge_index) + self.lin3(x)
        return x
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
loss_op = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)

def train():
    model.train()

    total_loss = 0
    for data in train_loader:
        num_graphs = data.num_graphs
        data.batch = None
        data = data.to(device)
        optimizer.zero_grad()
        loss = loss_op(model(data.x, data.edge_index), data.y)
        total_loss += loss.item() * num_graphs
        loss.backward()
        optimizer.step()
    return total_loss / len(train_loader.dataset)


def test(loader):
    model.eval()

    total_micro_f1 = 0
    for data in loader:
        with torch.no_grad():
            out = model(data.x.to(device), data.edge_index.to(device))
        pred = (out > 0).float().cpu()
        micro_f1 = metrics.f1_score(data.y, pred, average='micro')
        total_micro_f1 += micro_f1 * data.num_graphs
    return total_micro_f1 / len(loader.dataset)


for epoch in range(1, 101):
    loss = train()
    acc = test(val_loader)
    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))
acc=(test(test_loader))
print(acc)

import os.path as osp

import torch
import torch.nn.functional as F
from torch_geometric.datasets import PPI
from torch_geometric.data import DataLoader

from sklearn import metrics

#path = osp.join(osp.dirname(osp.realpath(__file__)), 'data', 'PPI')
train_dataset = PPI(root=".", split='train')
val_dataset = PPI(root=".",  split='test')
test_dataset = PPI(root=".", split='test')
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)


class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = GATConv(train_dataset.num_features, 256, heads=4)
        self.lin1 = torch.nn.Linear(train_dataset.num_features, 4 * 256)
        self.conv2 = GATConv(4 * 256, 256, heads=4)
        self.lin2 = torch.nn.Linear(4 * 256, 4 * 256)
        self.conv3 = GATConv(
            4 * 256, train_dataset.num_classes, heads=6, concat=False)
        self.lin3 = torch.nn.Linear(4 * 256, train_dataset.num_classes)

    def forward(self, x, edge_index):
        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))
        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))
        x = self.conv3(x, edge_index) + self.lin3(x)
        return x


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
loss_op = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)


def train():
    model.train()

    total_loss = 0
    for data in train_loader:
        num_graphs = data.num_graphs
        data.batch = None
        data = data.to(device)
        optimizer.zero_grad()
        loss = loss_op(model(data.x, data.edge_index), data.y)
        total_loss += loss.item() * num_graphs
        loss.backward()
        optimizer.step()
    return total_loss / len(train_loader.dataset)


def test(loader):
    model.eval()

    total_micro_f1 = 0
    for data in loader:
        with torch.no_grad():
            out = model(data.x.to(device), data.edge_index.to(device))
        pred = (out > 0).float().cpu()
        micro_f1 = metrics.f1_score(data.y, pred, average='micro')
        total_micro_f1 += micro_f1 * data.num_graphs
    return total_micro_f1 / len(loader.dataset)


for epoch in range(1, 101):
    loss = train()
    acc = test(val_loader)
    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))
acc=(test(test_loader))
print(acc)

import os.path as osp

import torch
import torch.nn.functional as F
from torch_geometric.datasets import PPI
from torch_geometric.data import DataLoader

from sklearn import metrics

#path = osp.join(osp.dirname(osp.realpath(__file__)), 'data', 'PPI')
train_dataset = PPI(root=".", split='train')
val_dataset = PPI(root=".",  split='val')
test_dataset = PPI(root=".", split='test')
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)
print(train_dataset.num_features)
for data in train_loader:
  print((data.edge_index).size())
  print(U.to_dense_adj(data.edge_index).squeeze(0).size())
  break
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = GCN_sum(train_dataset.num_features, 1024)
        self.lin1 = torch.nn.Linear(train_dataset.num_features,  1024)
        self.conv2 = GCN_sum(1024, 1024)
        self.lin2 = torch.nn.Linear(1024, 1024)
        self.conv3 = GCN_sum(1024, train_dataset.num_classes)
        self.lin3 = torch.nn.Linear(1024, train_dataset.num_classes)

    def forward(self, x, edge_index):
        x = F.elu(self.conv1(x, edge_index)+self.lin1(x))
        x = F.elu(self.conv2(x, edge_index)+self.lin2(x))
        x = self.conv3(x, edge_index)+self.lin3(x)
        return x
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
loss_op = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)

def train():
    model.train()

    total_loss = 0
    for data in train_loader:
        num_graphs = data.num_graphs
        data.batch = None
        data = data.to(device)
        #print(data.size())
        #print(data.edge_index.size())
        #print(data.x.size())
      #  print(adj.size())
        optimizer.zero_grad()
        loss = loss_op(model(data.x, data.edge_index), data.y)
        total_loss += loss.item() * num_graphs
        loss.backward()
        optimizer.step()
    return total_loss / len(train_loader.dataset)


def test(loader):
    model.eval()

    total_micro_f1 = 0
    for data in loader:
        with torch.no_grad():
            out = model(data.x.to(device), data.edge_index.to(device))
        pred = (out > 0).float().cpu()
        micro_f1 = metrics.f1_score(data.y, pred, average='micro')
        total_micro_f1 += micro_f1 * data.num_graphs
    return total_micro_f1 / len(loader.dataset)


for epoch in range(1, 101):
    loss = train()
    acc = test(val_loader)
    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))
acc=(test(test_loader))
print(acc)

print(acc)

import os.path as osp

import torch
import torch.nn.functional as F
from torch_geometric.datasets import PPI
from torch_geometric.data import DataLoader

from sklearn import metrics

#path = osp.join(osp.dirname(osp.realpath(__file__)), 'data', 'PPI')
train_dataset = PPI(root=".", split='train')
val_dataset = PPI(root=".",  split='test')
test_dataset = PPI(root=".", split='test')
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)


class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = GATConvv2(train_dataset.num_features, 256, heads=4)
        self.lin1 = torch.nn.Linear(train_dataset.num_features, 4 * 256)
        self.conv2 = GATConvv2(4 * 256, 256, heads=4)
        self.lin2 = torch.nn.Linear(4 * 256, 4 * 256)
        self.conv3 = GATConvv2(
            4 * 256, train_dataset.num_classes, heads=6, concat=False)
        self.lin3 = torch.nn.Linear(4 * 256, train_dataset.num_classes)

    def forward(self, x, edge_index):
        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))
        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))
        x = self.conv3(x, edge_index) + self.lin3(x)
        return x


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
loss_op = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)


def train():
    model.train()

    total_loss = 0
    for data in train_loader:
        num_graphs = data.num_graphs
        data.batch = None
        data = data.to(device)
        optimizer.zero_grad()
        loss = loss_op(model(data.x, data.edge_index), data.y)
        total_loss += loss.item() * num_graphs
        loss.backward()
        optimizer.step()
    return total_loss / len(train_loader.dataset)


def test(loader):
    model.eval()

    total_micro_f1 = 0
    for data in loader:
        with torch.no_grad():
            out = model(data.x.to(device), data.edge_index.to(device))
        pred = (out > 0).float().cpu()
        micro_f1 = metrics.f1_score(data.y, pred, average='micro')
        total_micro_f1 += micro_f1 * data.num_graphs
    return total_micro_f1 / len(loader.dataset)


for epoch in range(1, 101):
    loss = train()
    acc = test(val_loader)
    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))